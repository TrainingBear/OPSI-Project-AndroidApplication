{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Tambahkan blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "1LP4vJkj5BCx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Membuat model untuk sistem rekomendasi\n"
      ],
      "metadata": {
        "id": "PYDNzQ9WJ4zL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h6CRbtJ7KAi7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "# **Membuat desain model CNN untuk klasifikasi jenis - jenis tanah**\n",
        "\n",
        " kami mengambil dataset tanah dari [kagle](https://www.kaggle.com/datasets/fuadkahfi/dataset-tanah), kita mendapat 8 sampel jenis tanah dan total 880 datasets\n",
        "\n",
        "untuk model arsitektur, kami meniru style [VGGNet CNN architecture](https://en.wikipedia.org/wiki/VGGNet). berikut model arsitektur yang kami buat:\n",
        "> 320x320x3 --> 320x320x32 Conv1+ReLU --> max pooling --> 160x160x64 Conv2+ReLU --> max pooling --> 80x80x128 Conv3+ReLU --> max pooling --> Dropout(0.4) -> Flatten --> 1x1x128 fullyconnected1+ReLU --> Dropout(0.4) --> 1x1x8 fullyconnected2+softmax\n",
        "\n",
        "dengan model tersebut, kami berhasil mendapatkan hasil yang luar biasa. hanya 4% gap antara training acc dan validation acc    \n",
        "Epoch 100/100                                        \n",
        "21/21 ━━━━━━━━━━━━━━━━━━━━ 5s 258ms/step - accuracy: 0.9476 - loss: 0.1651 - val_accuracy: 0.9091 - val_loss: 0.3009\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "berikut model yang kami buat :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install required libraries\n",
        "\n",
        "!pip install keras~=3.8.0 \\\n",
        "  matplotlib~=3.10.0 \\\n",
        "  numpy~=2.0.0 \\\n",
        "  pandas~=2.2.0\n",
        "\n",
        "print('\\n\\nAll requirements successfully installed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNQJgIUxCZL7",
        "outputId": "63d9449b-23ac-4a6b-8643-2a486f1080e2",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras~=3.8.0 in /usr/local/lib/python3.12/dist-packages (3.8.0)\n",
            "Requirement already satisfied: matplotlib~=3.10.0 in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy~=2.0.0 in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas~=2.2.0 in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas~=2.2.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas~=2.2.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib~=3.10.0) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras~=3.8.0) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras~=3.8.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras~=3.8.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras~=3.8.0) (0.1.2)\n",
            "\n",
            "\n",
            "All requirements successfully installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dependencies\n",
        "\n",
        "import io\n",
        "\n",
        "# data\n",
        "import numpy as numpy\n",
        "import pandas as panda\n",
        "\n",
        "# machine learning\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# data visualization\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "\n",
        "# dataset\n",
        "import kagglehub\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "iNLA8xHaCwCD",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mempersiapkan dataset\n",
        "drive.mount('/content/drive')\n",
        "!unzip /content/drive/MyDrive/dataset_tanah.zip -d /content/dataset\n",
        "\n",
        "path = \"/content/dataset/\"\n",
        "\n",
        "batch = 32 #@param\n",
        "p = 320 #@param\n",
        "l = 320 #@param\n",
        "\n",
        "# data set yang akan di latih dan validasi\n",
        "split = 0.25 # @param {\"type\":\"number\"}\n",
        "\n",
        "training_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch,\n",
        "\n",
        "    validation_split=split,\n",
        "    subset=\"training\",\n",
        "    seed=1,\n",
        "\n",
        "    image_size=(p, l),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch,\n",
        "\n",
        "    validation_split=split,\n",
        "    subset=\"validation\",\n",
        "    seed=1,\n",
        "\n",
        "    image_size=(p, l),\n",
        "    shuffle=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLRodyOWPuhX",
        "outputId": "2e68bce6-3078-43f9-fb5b-2a6b845ba2d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  /content/drive/MyDrive/dataset_tanah.zip\n",
            "replace /content/dataset/Aluvial/aluvial-004.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Membuat model\n",
        "\n",
        "jenis = len(training_dataset.class_names)\n",
        "print(jenis)\n",
        "droput = 0.4 #@param\n",
        "\n",
        "augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\", seed=1),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(p, l, 3)),\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    augmentation,\n",
        "\n",
        "#    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "#    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "#    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Dropout(droput),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(droput),\n",
        "    tf.keras.layers.Dense(jenis, activation='softmax')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "VRI3AURYXeg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tahap Melatih model dan validaasi model\n",
        "\n",
        "rate = 0.0005 # @param {\"type\":\"number\"}\n",
        "epoch = 100 # @param {\"type\":\"integer\"}\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=rate),\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    training_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epoch\n",
        ")\n",
        "\n",
        "# export model menjadi .tflite\n",
        "model.save('model.keras')\n",
        "convert = tf.lite.TFLiteConverter.from_keras_model(tf.keras.models.load_model('model.keras'))\n",
        "tflite_model = convert.convert()\n",
        "with open(\"Tanah.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "e2EwaqHxmn3v",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Accuracy statistik graph\n",
        "\n",
        "model.summary()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xfyja47QS42b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mpqRXziW4rJs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Image classification with TensorFlow Lite Model Maker with TensorFlow 2.18.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDABAblytltI"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/tutorials/model_maker_image_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86-Nh4pMHqY"
      },
      "source": [
        "This notebook has been moved [here](https://www.tensorflow.org/lite/tutorials/model_maker_image_classification)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "aygorWvwYyhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/TrainingBear/OPSI-Project-AndroidApplication/blob/master/tensorflow_examples/lite/model_maker/demo/image_classification.ipynb#scrollTo=w7AdazbUlvDJ"
      ],
      "metadata": {
        "id": "w7AdazbUlvDJ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}