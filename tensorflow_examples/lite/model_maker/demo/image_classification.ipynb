{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Tambahkan blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "1LP4vJkj5BCx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Membuat model untuk sistem rekomendasi\n"
      ],
      "metadata": {
        "id": "PYDNzQ9WJ4zL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h6CRbtJ7KAi7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "# **Membuat desain model CNN untuk klasifikasi jenis - jenis tanah**\n",
        "\n",
        " kami mengambil dataset tanah dari [kagle](https://www.kaggle.com/datasets/fuadkahfi/dataset-tanah), kita mendapat 8 sampel jenis tanah dan total 880 datasets\n",
        "\n",
        "untuk model arsitektur, kami meniru style [VGGNet CNN architecture](https://en.wikipedia.org/wiki/VGGNet). berikut model arsitektur yang kami buat:\n",
        "> 320x320x3 --> 320x320x32 Conv1+ReLU --> max pooling --> 160x160x64 Conv2+ReLU --> max pooling --> 80x80x128 Conv3+ReLU --> max pooling --> Dropout(0.4) -> Flatten --> 1x1x128 fullyconnected1+ReLU --> Dropout(0.4) --> 1x1x8 fullyconnected2+softmax\n",
        "\n",
        "dengan model tersebut, kami berhasil mendapatkan hasil yang luar biasa. hanya 4% gap antara training acc dan validation acc    \n",
        "Epoch 100/100                                        \n",
        "21/21 ━━━━━━━━━━━━━━━━━━━━ 5s 258ms/step - accuracy: 0.9476 - loss: 0.1651 - val_accuracy: 0.9091 - val_loss: 0.3009\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "berikut model yang kami buat :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install required libraries\n",
        "\n",
        "!pip install keras~=3.8.0 \\\n",
        "  matplotlib~=3.10.0 \\\n",
        "  numpy~=2.0.0 \\\n",
        "  pandas~=2.2.0\n",
        "\n",
        "print('\\n\\nAll requirements successfully installed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNQJgIUxCZL7",
        "outputId": "8e051b34-649c-4588-b3f9-e070f414b62c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras~=3.8.0\n",
            "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: matplotlib~=3.10.0 in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy~=2.0.0 in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas~=2.2.0 in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras~=3.8.0) (25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.10.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas~=2.2.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas~=2.2.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib~=3.10.0) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras~=3.8.0) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras~=3.8.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras~=3.8.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras~=3.8.0) (0.1.2)\n",
            "Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m1.2/1.3 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.10.0\n",
            "    Uninstalling keras-3.10.0:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dependencies\n",
        "\n",
        "import io\n",
        "\n",
        "# data\n",
        "import numpy as numpy\n",
        "import pandas as panda\n",
        "\n",
        "# machine learning\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# data visualization\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "\n",
        "# dataset\n",
        "import kagglehub\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "iNLA8xHaCwCD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mempersiapkan dataset\n",
        "# drive.mount('/content/drive')\n",
        "# !unzip /content/drive/MyDrive/dataset_tanah.zip -d /content/dataset\n",
        "# dataset\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"fuadkahfi/dataset-tanah\")+\"/Tanah\"\n",
        "print(path)\n",
        "\n",
        "\n",
        "batch = 32 #@param\n",
        "p = 320 #@param\n",
        "l = 320 #@param\n",
        "\n",
        "# data set yang akan di latih dan validasi\n",
        "split = 0.2 # @param {\"type\":\"number\"}\n",
        "\n",
        "raw_training_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch,\n",
        "\n",
        "    validation_split=split,\n",
        "    subset=\"training\",\n",
        "    seed=1,\n",
        "\n",
        "    image_size=(p, l),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "training_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch,\n",
        "\n",
        "    validation_split=split,\n",
        "    subset=\"training\",\n",
        "    seed=1,\n",
        "\n",
        "    image_size=(p, l),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "# Load 80% train, 20% temp (val + test)\n",
        "temp_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch,\n",
        "\n",
        "    validation_split=split,\n",
        "    subset=\"validation\",\n",
        "    seed=1,\n",
        "    image_size=(p, l),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "temp_dataset = temp_dataset.shuffle(buffer_size=1000, seed=1)\n",
        "\n",
        "# Now split temp_dataset into val and test manually\n",
        "validation_dataset = temp_dataset.take(int(0.5 * len(temp_dataset)))\n",
        "test_dataset = temp_dataset.skip(int(0.5 * len(temp_dataset)))\n",
        "\n",
        "# training_dataset = raw_training_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# validation_dataset = validation_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "# test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "class_names = raw_training_dataset.class_names\n",
        "print(\"Class names:\", class_names)\n",
        "def count_dataset(dataset):\n",
        "    total = 0\n",
        "    for images, labels in dataset:\n",
        "        total += images.shape[0]  # batch size may be smaller on last batch\n",
        "    return total\n",
        "\n",
        "print(\"Training samples:\", count_dataset(training_dataset)/880*100)\n",
        "print(\"Validation samples:\", count_dataset(validation_dataset)/880*100)\n",
        "print(\"Test samples:\", count_dataset(test_dataset)/880*100)\n"
      ],
      "metadata": {
        "id": "gLRodyOWPuhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Membuat model\n",
        "\n",
        "jenis = len(raw_training_dataset.class_names)\n",
        "print(jenis)\n",
        "droput = 0.4 #@param\n",
        "\n",
        "augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomZoom((0.2, 0.2)),\n",
        "    tf.keras.layers.RandomRotation(0.04),\n",
        "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
        "    # tf.keras.layers.RandomContrast(0.1),\n",
        "    # tf.keras.layers.RandomBrightness(0.1),\n",
        "    # AddGaussianNoise(0.01)\n",
        "])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(p, l, 3)),\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    augmentation,\n",
        "\n",
        "#    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "#    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "#    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Dropout(droput),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(droput),\n",
        "    tf.keras.layers.Dense(jenis, activation='softmax')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "VRI3AURYXeg6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tahap Melatih model dan validaasi model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,            # tolerates 7 bad epochs\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "rate = 0.00025 # @param {\"type\":\"number\"}\n",
        "epoch = 100 # @param {\"type\":\"integer\"}\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=rate),\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    training_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epoch,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# export model menjadi .tflite\n",
        "model.save('model.keras')\n",
        "convert = tf.lite.TFLiteConverter.from_keras_model(tf.keras.models.load_model('model.keras'))\n",
        "tflite_model = convert.convert()\n",
        "with open(\"Tanah.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "e2EwaqHxmn3v",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Step 1: Get all images and labels from your test dataset into numpy arrays\n",
        "test_images_list = []\n",
        "test_labels_list = []\n",
        "for images_batch, labels_batch in test_dataset:\n",
        "    test_images_list.append(images_batch.numpy())\n",
        "    test_labels_list.append(labels_batch.numpy())\n",
        "\n",
        "y_true = numpy.concatenate(test_labels_list, axis=0)\n",
        "all_test_images = numpy.concatenate(test_images_list, axis=0)\n",
        "\n",
        "# Step 2: Get model predictions using the collected numpy array of images\n",
        "y_pred_probs = model.predict(all_test_images)\n",
        "y_pred = numpy.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Step 3: Get the class names from the training dataset (or any dataset directly from the directory)\n",
        "test_class_names = raw_training_dataset.class_names\n",
        "print(test_class_names)\n",
        "\n",
        "labels = list(range(len(test_class_names)))\n",
        "\n",
        "report = classification_report(\n",
        "    y_true, y_pred,\n",
        "    labels=labels,\n",
        "    target_names=test_class_names,\n",
        "    output_dict=True,\n",
        "    zero_division=0  # avoids divide-by-zero warnings\n",
        ")\n",
        "\n",
        "df = panda.DataFrame(report).transpose()\n",
        "print(df)\n",
        "df.to_csv(\"precision_table.csv\", index=True)"
      ],
      "metadata": {
        "id": "xfyja47QS42b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mpqRXziW4rJs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Image classification with TensorFlow Lite Model Maker with TensorFlow 2.18.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDABAblytltI"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/tutorials/model_maker_image_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86-Nh4pMHqY"
      },
      "source": [
        "This notebook has been moved [here](https://www.tensorflow.org/lite/tutorials/model_maker_image_classification)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "aygorWvwYyhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/TrainingBear/OPSI-Project-AndroidApplication/blob/master/tensorflow_examples/lite/model_maker/demo/image_classification.ipynb#scrollTo=w7AdazbUlvDJ"
      ],
      "metadata": {
        "id": "w7AdazbUlvDJ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}